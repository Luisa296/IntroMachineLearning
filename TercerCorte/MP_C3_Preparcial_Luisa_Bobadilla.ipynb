{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "0b418101",
      "metadata": {
        "id": "0b418101"
      },
      "source": [
        "# üß™ Pre‚ÄëParcial ‚Äì M√©todos Predictivos\n",
        "**Supervisado vs. No Supervisado**\n",
        "\n",
        "> Completa las celdas con `TODO` y ejecuta *Runtime ‚Üí Run all* antes de entregar.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5b235da4",
      "metadata": {
        "id": "5b235da4"
      },
      "source": [
        "### Contenido\n",
        "1. [Parte A ‚Äì Teor√≠a](#parte-a)\n",
        "2. [Parte B ‚Äì Pr√°ctica](#parte-b)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6bf1ec3f",
      "metadata": {
        "id": "6bf1ec3f"
      },
      "source": [
        "## Parte¬†A ‚Äî Cuestionario Te√≥rico (40‚ÄØpts)\n",
        "Responde **brevemente** en las celdas Markdown que siguen a cada pregunta.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "29324086",
      "metadata": {
        "id": "29324086"
      },
      "source": [
        "#### 1Ô∏è‚É£ **Variable objetivo (y)** ‚Äì Def√≠nela y da un ejemplo en este dataset.\n",
        "\n",
        "*Respuesta:* <!-- TODO -->\n",
        "\n",
        "La variable objetivo (y) es la que se quiere predecir en un modelo. En un dataset de clientes, por ejemplo, la variable objetivo puede ser si realizan o no una compra.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "00e18666",
      "metadata": {
        "id": "00e18666"
      },
      "source": [
        "#### 2Ô∏è‚É£ Ordena las fases del *pipeline* de ML: `Modelado`, `Pre‚Äëprocesamiento`, `EDA`, `Evaluaci√≥n`, `Insight de negocio`.\n",
        "\n",
        "*Respuesta:* <!-- TODO -->\n",
        "\n",
        "Problema ‚Üí EDA ‚Üí Pre-procesamiento ‚Üí Modelado ‚Üí Evaluaci√≥n ‚Üí Insight de negocio\n",
        "Este orden permite primero entender el problema desde el negocio, explorar los datos, prepararlos, construir el modelo, evaluarlo y tomar desiciones.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "910a8986",
      "metadata": {
        "id": "910a8986"
      },
      "source": [
        "#### 3Ô∏è‚É£ Para un problema de **clases desbalanceadas**, ¬øqu√© m√©trica priorizar√≠as y por qu√©?\n",
        "\n",
        "*Respuesta:* <!-- TODO -->\n",
        "\n",
        "Priorizar√≠a el F1-score porque equilibra precisi√≥n y recall, lo cual es vital cuando las clases no est√°n distribuidas equitativamente. La exactitud (accuracy) puede ser enga√±osa si la clase minoritaria es la m√°s importante."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4de30673",
      "metadata": {
        "id": "4de30673"
      },
      "source": [
        "#### 4Ô∏è‚É£ Describe **overfitting** y c√≥mo lo detectar√≠as en la pr√°ctica.\n",
        "\n",
        "*Respuesta:* <!-- TODO -->\n",
        "\n",
        "El overfitting es cuando un modelo aprende tanto los patrones como el ruido del conjunto de entrenamiento, lo que lo hace ineficiente al generalizar. Se detecta comparando el rendimiento, si el modelo tiene alta precisi√≥n en entrenamiento pero bajo desempe√±o en validaci√≥n o test, probablemente hay sobreajuste.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e3fbcf52",
      "metadata": {
        "id": "e3fbcf52"
      },
      "source": [
        "#### 5Ô∏è‚É£ Completa: *K‚Äëmeans es un algoritmo de _________ porque ________.*\n",
        "\n",
        "*Respuesta:* <!-- TODO -->\n",
        "\n",
        "K-means es un algoritmo de clustering no supervisado porque agrupa los datos en k cl√∫steres sin requerir etiquetas, bas√°ndose en la similitud.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "033b889a",
      "metadata": {
        "id": "033b889a"
      },
      "source": [
        "#### 7Ô∏è‚É£ En **regresi√≥n**, ¬øc√≥mo es la variable objetivo? (cualitativa, cuantitativa, binaria‚Ä¶).\n",
        "\n",
        "*Respuesta:* <!-- TODO -->\n",
        "\n",
        "Es cuantitativa ya que la regresi√≥n busca predecir valores num√©ricos como el precio de una casa o el ingreso mensual.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aea04580",
      "metadata": {
        "id": "aea04580"
      },
      "source": [
        "#### 8Ô∏è‚É£ Menciona 2 t√©cnicas comunes de **pre‚Äëprocesamiento de texto**.\n",
        "\n",
        "*Respuesta:* <!-- TODO -->\n",
        "\n",
        "1. Normalizaci√≥n: Convertir el texto a un formato est√°ndar, por ejemplo poner todo en min√∫sculas o eliminar signos de puntuaci√≥n.\n",
        "\n",
        "2. Eliminaci√≥n de palabras vac√≠as: Eliminar palabras comunes que no aportan mucho significado al an√°lisis, por ejemplo \"el\" o \"la\"."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7dc106a4",
      "metadata": {
        "id": "7dc106a4"
      },
      "source": [
        "#### 9Ô∏è‚É£ ¬øQu√© representa el par√°metro *k* en K‚Äëmeans y qu√© ocurre si es muy grande?\n",
        "\n",
        "*Respuesta:* <!-- TODO -->\n",
        "\n",
        "K representa el n√∫mero de cl√∫steres que queremos formar. Si se elige un valor muy grande, los cl√∫steres pueden volverse demasiado peque√±os, representando ruido o subdivisiones irrelevantes, lo cual puede perjudicar la interpretaci√≥n y generalizaci√≥n del modelo.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "86dcdc0c",
      "metadata": {
        "id": "86dcdc0c"
      },
      "source": [
        "#### üîü Define brevemente un **embedding** en NLP y su utilidad.\n",
        "\n",
        "*Respuesta:* <!-- TODO -->\n",
        "\n",
        "Un embedding es una representaci√≥n num√©rica densa de palabras en un espacio vectorial. A diferencia del one-hot encoding, los embeddings capturan relaciones sem√°nticas como por ejemplo \"rey\" y \"reina\" est√°n cerca en el espacio. Son fundamentales en NLP porque permiten que los modelos comprendan mejor el significado contextual del lenguaje."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2801cc8c",
      "metadata": {
        "id": "2801cc8c"
      },
      "source": [
        "## <a id='parte-b'></a>üíª Parte¬†B ‚Äî Pr√°ctica (60‚ÄØpts)\n",
        "Trabajar√°s con la tabla de rese√±as de Amazon que contiene, entre otras, las columnas `reviewerID`, `asin`, `helpful`, `reviewText`, `overall`, `summary`, `unixReviewTime`, `day_diff`.\n",
        "\n",
        "> **Objetivos**\n",
        "> 1. Clasificar rese√±as positivas (rating ‚â•‚ÄØ4) vs negativas.\n",
        "> 2. Agrupar rese√±as con K‚Äëmeans y perfilar clusters.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Columnas de la tabla\n",
        "üìÑ Reviewer ID: Unique identifier for the reviewer.\n",
        "\n",
        "üì¶ ASIN: Amazon Standard Identification Number for the product.\n",
        "\n",
        "üë§ Reviewer Name: Name of the reviewer.\n",
        "\n",
        "üëç Helpful: Number of helpful votes the review received.\n",
        "\n",
        "üìù Review Text: The content of the review written by the customer.\n",
        "\n",
        "‚≠ê Overall Rating: The overall rating given to the product (ranging from 1 to 5 stars).\n",
        "\n",
        "üì∞ Summary: A brief summary of the review.\n",
        "\n",
        "üï∞Ô∏è Unix Review Time: The time the review was posted in Unix timestamp format.\n",
        "\n",
        "üìÖ Review Time: The time the review was posted in a readable date format.\n",
        "\n",
        "üìÜ Day Difference: The number of days between the review date and the current date.\n",
        "\n",
        "‚úîÔ∏è Helpful Yes: Number of positive helpful votes.\n",
        "\n",
        "üî¢ Total Votes: Total number of votes the review received."
      ],
      "metadata": {
        "id": "7hsADh7PqTRf"
      },
      "id": "7hsADh7PqTRf"
    },
    {
      "cell_type": "markdown",
      "id": "37f40c50",
      "metadata": {
        "id": "37f40c50"
      },
      "source": [
        "### 1. Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e0037397",
      "metadata": {
        "id": "e0037397"
      },
      "outputs": [],
      "source": [
        "# Instala paquetes extra si los necesitas\n",
        "# !pip install shap\n",
        "\n",
        "import pandas as pd, numpy as np, matplotlib.pyplot as plt, seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, ConfusionMatrixDisplay\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import silhouette_score\n",
        "import warnings, random, os\n",
        "warnings.filterwarnings('ignore')\n",
        "random.seed(42)\n",
        "np.random.seed(42)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bb527f5e",
      "metadata": {
        "id": "bb527f5e"
      },
      "source": [
        "### 2. Carga del dataset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://github.com/javierherrera1996/IntroMachineLearning/raw/refs/heads/main/TercerCorte/amazon_review.csv.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JXgp7kP5oj1e",
        "outputId": "7c3fe064-cfa3-4f95-ce39-0d49b8d1cd4c"
      },
      "id": "JXgp7kP5oj1e",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-05-31 20:38:39--  https://github.com/javierherrera1996/IntroMachineLearning/raw/refs/heads/main/TercerCorte/amazon_review.csv.zip\n",
            "Resolving github.com (github.com)... 140.82.116.4\n",
            "Connecting to github.com (github.com)|140.82.116.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/javierherrera1996/IntroMachineLearning/refs/heads/main/TercerCorte/amazon_review.csv.zip [following]\n",
            "--2025-05-31 20:38:40--  https://raw.githubusercontent.com/javierherrera1996/IntroMachineLearning/refs/heads/main/TercerCorte/amazon_review.csv.zip\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 721801 (705K) [application/zip]\n",
            "Saving to: ‚Äòamazon_review.csv.zip.1‚Äô\n",
            "\n",
            "amazon_review.csv.z 100%[===================>] 704.88K  --.-KB/s    in 0.04s   \n",
            "\n",
            "2025-05-31 20:38:40 (17.0 MB/s) - ‚Äòamazon_review.csv.zip.1‚Äô saved [721801/721801]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip amazon_review.csv.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AK_yVUSMoovr",
        "outputId": "a5fb5caf-926b-486d-9b86-5a7b7b196a29"
      },
      "id": "AK_yVUSMoovr",
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Archive:  amazon_review.csv.zip\n",
            "replace amazon_review.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('amazon_review.csv')\n",
        "df.head()"
      ],
      "metadata": {
        "id": "nuH4Usfbok5j"
      },
      "id": "nuH4Usfbok5j",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "2e62da97",
      "metadata": {
        "id": "2e62da97"
      },
      "source": [
        "### 3. Exploratory¬†Data¬†Analysis (EDA)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b26855f6",
      "metadata": {
        "id": "b26855f6"
      },
      "outputs": [],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "Nz4iVp3nxL2Y"
      },
      "id": "Nz4iVp3nxL2Y",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe()"
      ],
      "metadata": {
        "id": "VKSnPMOXxPKn"
      },
      "id": "VKSnPMOXxPKn",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.isna().sum()"
      ],
      "metadata": {
        "id": "QMcbUlFVxSCO"
      },
      "id": "QMcbUlFVxSCO",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nDistribuci√≥n de la columna 'overall' (rating):\")\n",
        "print(df['overall'].value_counts())\n",
        "print(df['overall'].value_counts(normalize=True)) # En porcentajes\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.countplot(x='overall', data=df)\n",
        "plt.title('Distribuci√≥n de Ratings (overall)')\n",
        "plt.xlabel('Rating')\n",
        "plt.ylabel('Cantidad de Rese√±as')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "73h0bN63xXzS"
      },
      "id": "73h0bN63xXzS",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "db24870b",
      "metadata": {
        "id": "db24870b"
      },
      "source": [
        "### 4. Limpieza & Feature Engineering"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.1 Cree un revie_datetime usando unixReviewTime y la funcion pd.to_datetime"
      ],
      "metadata": {
        "id": "263RZ7LVppCJ"
      },
      "id": "263RZ7LVppCJ"
    },
    {
      "cell_type": "code",
      "source": [
        "df['review_datetime'] = pd.to_datetime(df['unixReviewTime'], unit='s')\n",
        "df.head()"
      ],
      "metadata": {
        "id": "aaRVdrUBp1r5"
      },
      "id": "aaRVdrUBp1r5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.2 Cree una columna positive que sea igual a 1 cuando overall sea mayor o igual  a 4."
      ],
      "metadata": {
        "id": "vghJGFePp1L6"
      },
      "id": "vghJGFePp1L6"
    },
    {
      "cell_type": "code",
      "source": [
        "df['positive'] = (df['overall'] >= 4).astype(int)\n",
        "df.head()"
      ],
      "metadata": {
        "id": "IwtJPdBFposv"
      },
      "id": "IwtJPdBFposv",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.3 Cree una columna text que sea la union de summary y review text: text_cols['summary'] + '. ' + text_cols['reviewText']).str.strip()"
      ],
      "metadata": {
        "id": "XitrTtwNqugO"
      },
      "id": "XitrTtwNqugO"
    },
    {
      "cell_type": "code",
      "source": [
        "text_cols = df[['summary', 'reviewText']].fillna('') # fillna handles potential NaN values\n",
        "df['text'] = (text_cols['summary'] + '. ' + text_cols['reviewText']).str.strip()\n",
        "df.head()"
      ],
      "metadata": {
        "id": "dJsEMeTHrDxp"
      },
      "id": "dJsEMeTHrDxp",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.4 Elimine las columnas que no puede usar en el modleo de clasificacion"
      ],
      "metadata": {
        "id": "VVPUjYq-q_1f"
      },
      "id": "VVPUjYq-q_1f"
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.drop(['reviewerID', 'asin', 'reviewerName', 'helpful', 'overall', 'unixReviewTime', 'reviewTime', 'day_diff', 'helpful_yes', 'total_vote'], axis=1)\n",
        "df.head()"
      ],
      "metadata": {
        "id": "rK_Wjjig4qK_"
      },
      "id": "rK_Wjjig4qK_",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "bRtcB4xM5JFE"
      },
      "id": "bRtcB4xM5JFE",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "        df['text'], df['positive'], test_size=0.3, stratify=df['positive'], random_state=42)\n",
        "\n",
        "pipe = Pipeline([\n",
        "    ('tfidf', TfidfVectorizer(max_features=10000)),\n",
        "    ('clf',  LogisticRegression(max_iter=1000, class_weight='balanced', n_jobs=-1, random_state=42))\n",
        "])\n",
        "\n",
        "# pipe.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "xUpS8Cjbs4YS"
      },
      "id": "xUpS8Cjbs4YS",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "e98db953",
      "metadata": {
        "id": "e98db953"
      },
      "source": [
        "### 5. Modelo de Clasificaci√≥n ‚Äì Supervisado (25‚ÄØpts)\n",
        "  * Ralice una regreison logistica y use la columa positive que creoo como target, entregue una matriz de confusion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f408a4bc",
      "metadata": {
        "id": "f408a4bc"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "pipe.fit(X_train, y_train)\n",
        "y_pred = pipe.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cm = confusion_matrix(y_test, y_pred)\n",
        "cm"
      ],
      "metadata": {
        "id": "rI21FCrZ6kPR"
      },
      "id": "rI21FCrZ6kPR",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Negativo (0)', 'Positivo (1)'], yticklabels=['Negativo (0)', 'Positivo (1)'])\n",
        "plt.xlabel('Predicho')\n",
        "plt.ylabel('Real')\n",
        "plt.title('Matriz de Confusi√≥n')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Vvw7_CRr6pNx"
      },
      "id": "Vvw7_CRr6pNx",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nReporte de Clasificaci√≥n:\")\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "id": "WX6m6qFQ6zA7"
      },
      "id": "WX6m6qFQ6zA7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "a689272e",
      "metadata": {
        "id": "a689272e"
      },
      "source": [
        "### 6. Clustering K‚Äëmeans ‚Äì No Supervisado (20‚ÄØpts)\n",
        "Haga un modelo para agrupasr los comentarios: vectorizer = TfidfVectorizer(max_features=10000)\n",
        "X_vec = vectorizer.fit_transform(df['text'])\n",
        "\n",
        "y cre una variable que se llame clsuter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c4de9f6c",
      "metadata": {
        "id": "c4de9f6c"
      },
      "outputs": [],
      "source": [
        "vectorizer = TfidfVectorizer(max_features=10000)\n",
        "X_vec = vectorizer.fit_transform(df['text'])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "k = 5\n",
        "kmeans = KMeans(n_clusters=k, random_state=42, n_init=10) # n_init para evitar advertencia\n",
        "cluster = kmeans.fit_predict(X_vec)"
      ],
      "metadata": {
        "id": "a64sQks07AhE"
      },
      "id": "a64sQks07AhE",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['cluster'] = cluster\n",
        "df.head()"
      ],
      "metadata": {
        "id": "BoyD32Li7HLr"
      },
      "id": "BoyD32Li7HLr",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nDistribuci√≥n de rese√±as por cluster:\")\n",
        "print(df['cluster'].value_counts())"
      ],
      "metadata": {
        "id": "yaMYo74o8rvS"
      },
      "id": "yaMYo74o8rvS",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "0e817a5b",
      "metadata": {
        "id": "0e817a5b"
      },
      "source": [
        "#### Perfil de clusters: Entregue una descriptiva de que contenia cada clster en termino de las otras variables:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: Perfil de clusters: Entregue una descriptiva de que contenia cada clster en termino de las otras variables\n",
        "\n",
        "print(\"\\n--- Perfil de Clusters ---\")\n",
        "\n",
        "# Iterar sobre cada cluster para analizar su perfil\n",
        "for cluster_id in sorted(df['cluster'].unique()):\n",
        "    print(f\"\\n--- Cluster {cluster_id} ---\")\n",
        "\n",
        "    # Filtrar el DataFrame para el cluster actual\n",
        "    cluster_df = df[df['cluster'] == cluster_id]\n",
        "    num_reviews = len(cluster_df)\n",
        "\n",
        "    print(f\"Total de rese√±as en este cluster: {num_reviews}\")\n",
        "\n",
        "    # An√°lisis de la variable 'positive' (sentimiento binario)\n",
        "    print(\"\\nDistribuci√≥n de Sentimiento (Positivo/Negativo):\")\n",
        "    print(cluster_df['positive'].value_counts(normalize=True)) # Mostrar porcentajes\n",
        "\n",
        "    # An√°lisis de la variable 'helpful' (votos √∫tiles) - estad√≠sticas descriptivas\n",
        "    # Aseg√∫rate de que 'helpful' es num√©rico. Si es una cadena, puedes necesitar convertirla.\n",
        "    # Aqu√≠ asumimos que 'helpful' en el df original ya era num√©rico o se limpi√≥ antes del drop.\n",
        "    # Si usaste df_cleaned para el clustering, podr√≠as necesitar re-unir las columnas relevantes.\n",
        "    # Si el clustering se hizo sobre df['text'], entonces podemos usar el df original.\n",
        "    if 'helpful' in cluster_df.columns:\n",
        "        print(\"\\nEstad√≠sticas descriptivas de Votos √ötiles ('helpful'):\")\n",
        "        print(cluster_df['helpful'].describe())\n",
        "    else:\n",
        "        print(\"\\nLa columna 'helpful' no est√° disponible en el DataFrame del cluster.\")\n",
        "\n",
        "\n",
        "    # An√°lisis de la variable 'review_length'\n",
        "    if 'review_length' in cluster_df.columns:\n",
        "        print(\"\\nEstad√≠sticas descriptivas de la Longitud de la Rese√±a:\")\n",
        "        print(cluster_df['review_length'].describe())\n",
        "    else:\n",
        "         print(\"\\nLa columna 'review_length' no est√° disponible en el DataFrame del cluster.\")\n",
        "\n",
        "\n",
        "    # An√°lisis de las palabras m√°s frecuentes en el texto del cluster\n",
        "    # Puedes tomar una muestra si el cluster es muy grande\n",
        "    sample_text = ' '.join(cluster_df['text'].sample(min(1000, num_reviews), replace=True).tolist())\n",
        "\n",
        "    # Usar el mismo vectorizador TF-IDF (o uno nuevo si quieres) para analizar el texto del cluster\n",
        "    # Para simple frecuencia, puedes usar CountVectorizer o analizar la cadena directamente\n",
        "    from collections import Counter\n",
        "    import re\n",
        "\n",
        "    words = re.findall(r'\\b\\w+\\b', sample_text.lower()) # Extrae palabras, convierte a min√∫sculas\n",
        "    stop_words = set(['el', 'la', 'los', 'las', 'un', 'una', 'unos', 'unas', 'de', 'en', 'y', 'a', 'que', 'es', 'con', 'para', 'del', 'al', 'se', 'por', 'su', 'sus', 'como', 'mas', 'pero', 'este', 'esta', 'si', 'no', 'cuando', 'donde', 'porque', 'muy', 'mi', 'mis', 'tu', 'tus', 'el', 'ella', 'nosotros', 'vosotros', 'ellos', 'las', 'los']) # Ejemplo de stop words en espa√±ol\n",
        "\n",
        "    # Filtrar stop words\n",
        "    filtered_words = [word for word in words if word not in stop_words and len(word) > 1]\n",
        "\n",
        "    word_counts = Counter(filtered_words)\n",
        "    print(\"\\nPalabras m√°s frecuentes (Top 10):\")\n",
        "    print(word_counts.most_common(10))\n",
        "\n",
        "    print(\"-\" * (len(f\"--- Cluster {cluster_id} ---\"))) # Separador para el siguiente cluster"
      ],
      "metadata": {
        "id": "OilyFHNA-Ypw"
      },
      "id": "OilyFHNA-Ypw",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "d4d51cd5",
      "metadata": {
        "id": "d4d51cd5"
      },
      "source": [
        "### 7. Insight & Recomendaciones (15‚ÄØpts)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ccca05a5",
      "metadata": {
        "id": "ccca05a5"
      },
      "source": [
        "*Escribe aqu√≠ tu an√°lisis de c√≥mo se relacionan los errores del modelo con los clusters y propone 1‚Äë2 acciones de negocio basadas en tus hallazgos.*\n",
        "\n",
        "<!-- TODO -->"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**An√°lisis de errores del modelo y su relaci√≥n con los grupos (clusters):**\n",
        "El modelo de regresi√≥n log√≠stica que usamos para clasificar rese√±as como positivas (4 o m√°s estrellas) o negativas muestra buenos resultados generales, con un 92% de precisi√≥n. Sin embargo, si miramos m√°s de cerca la matriz de confusi√≥n y el informe de desempe√±o, vemos que a√∫n hay puntos a mejorar, sobre todo al identificar rese√±as negativas, que son menos comunes.\n",
        "\n",
        "- Falsos negativos (FN): El modelo clasific√≥ 90 rese√±as negativas como si fueran positivas. Esto hace que su capacidad para detectar rese√±as negativas (recall) sea baja, con solo un 78% de aciertos en esa clase. Esto es preocupante, ya que se pueden perder oportunidades de detectar fallas en el producto o servicio.\n",
        "\n",
        "- Falsos positivos (FP): El modelo tambi√©n clasific√≥ 31 rese√±as positivas como si fueran negativas. Aunque no son muchas, pueden llevar a decisiones innecesarias o malinterpretaciones sobre la satisfacci√≥n del cliente.\n",
        "\n",
        "- Desbalance entre clases: Solo el 20% de las rese√±as son negativas, lo que hace m√°s dif√≠cil para el modelo aprender a identificarlas correctamente. Aunque usamos una t√©cnica para balancear el modelo (class_weight='balanced'), el problema persiste, algo com√∫n cuando hay mucha m√°s cantidad de una clase que de otra.\n",
        "\n",
        "- Relaci√≥n con los grupos (clusters):\n",
        "Al analizar los grupos creados con clustering, vimos que algunos tienen m√°s rese√±as negativas que otros. Por ejemplo, el Cluster 1 tiene casi un 23% de rese√±as negativas, mientras que otros, como el Cluster 0 y el 2, son casi totalmente positivos. Es probable que muchos de los errores del modelo (como los falsos negativos) est√©n dentro de los grupos con opiniones mixtas, donde el texto es m√°s dif√≠cil de interpretar. En cambio, los clusters con rese√±as mayoritariamente positivas ayudan a que el modelo tenga un buen rendimiento general.\n",
        "\n",
        "**Recomendaciones para el negocio:**\n",
        "1. Analizar errores en clusters espec√≠ficos: Se deber√≠an revisar las rese√±as que el modelo clasific√≥ mal (especialmente las negativas que trat√≥ como positivas), enfoc√°ndose en los grupos con m√°s rese√±as negativas, como el Cluster 1. Esto puede hacerse de forma manual o autom√°tica para ver si hay palabras, tonos (como sarcasmo) o temas que el modelo no est√° entendiendo. Esta informaci√≥n servir√≠a para mejorar el procesamiento del texto o incluso probar modelos m√°s avanzados.\n",
        "\n",
        "2. Usar los clusters como apoyo: Los clusters pueden ayudar a entender mejor las rese√±as antes de clasificarlas. Por ejemplo, se puede dar prioridad a los clusters con m√°s rese√±as negativas para an√°lisis m√°s detallados. Tambi√©n se podr√≠an crear modelos especializados para cada cluster. Adem√°s, el an√°lisis de las palabras comunes en cada grupo puede dar pistas sobre lo que m√°s gusta o molesta a los clientes, lo cual puede usarse para tomar decisiones en marketing, producto o servicio al cliente."
      ],
      "metadata": {
        "id": "gxZTJ68wA8Fw"
      },
      "id": "gxZTJ68wA8Fw"
    },
    {
      "cell_type": "markdown",
      "id": "e3023398",
      "metadata": {
        "id": "e3023398"
      },
      "source": [
        "\n",
        "## ‚úÖ 8. Checklist final\n",
        "- [ ] Notebook corre sin errores\n",
        "- [ ] Respuestas te√≥ricas completadas\n",
        "- [ ] Comentarios claros y semillas fijas\n",
        "- [ ] 5 slides creadas y exportadas a PDF\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}